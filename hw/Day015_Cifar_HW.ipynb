{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 42s 0us/step\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "    mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "    X_train = (X_train-mean)/(std+1e-7)\n",
    "    X_test = (X_test-mean)/(std+1e-7) \n",
    "    return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot = OneHotEncoder()\n",
    "y_train = one_hot.fit_transform(y_train).toarray()\n",
    "y_test = one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 216s 4ms/step - loss: 1.3917 - acc: 0.5113\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.9564 - acc: 0.6647\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.7426 - acc: 0.7381\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 224s 4ms/step - loss: 0.6054 - acc: 0.7874\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 0.4903 - acc: 0.8257\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.3921 - acc: 0.8616\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 0.3014 - acc: 0.8915\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.2351 - acc: 0.9174\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 223s 4ms/step - loss: 0.1806 - acc: 0.9365\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 224s 4ms/step - loss: 0.1566 - acc: 0.9444\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 223s 4ms/step - loss: 0.1297 - acc: 0.9543\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 220s 4ms/step - loss: 0.1122 - acc: 0.9610\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 224s 4ms/step - loss: 0.1093 - acc: 0.9621\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 231s 5ms/step - loss: 0.0968 - acc: 0.9659\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 234s 5ms/step - loss: 0.0968 - acc: 0.9654\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 222s 4ms/step - loss: 0.0822 - acc: 0.9712\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 223s 4ms/step - loss: 0.0644 - acc: 0.9777\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 228s 5ms/step - loss: 0.0768 - acc: 0.9730\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 233s 5ms/step - loss: 0.0783 - acc: 0.9727\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 226s 5ms/step - loss: 0.0615 - acc: 0.9789\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 234s 5ms/step - loss: 0.0510 - acc: 0.9822\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 223s 4ms/step - loss: 0.0683 - acc: 0.9771\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 233s 5ms/step - loss: 0.0557 - acc: 0.9808\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 224s 4ms/step - loss: 0.0547 - acc: 0.9812\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 224s 4ms/step - loss: 0.0553 - acc: 0.9806\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 225s 5ms/step - loss: 0.0480 - acc: 0.9837\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 216s 4ms/step - loss: 0.0524 - acc: 0.9821\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0493 - acc: 0.9834\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0421 - acc: 0.9858\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0487 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 211s 4ms/step - loss: 0.0417 - acc: 0.9862\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0430 - acc: 0.9852\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0490 - acc: 0.9834\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0337 - acc: 0.9887\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0346 - acc: 0.9881\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0397 - acc: 0.9865\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0404 - acc: 0.9858\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0325 - acc: 0.9894\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.0312 - acc: 0.9890\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0392 - acc: 0.9869\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0408 - acc: 0.9864\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0299 - acc: 0.9900\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0287 - acc: 0.9903\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.0303 - acc: 0.9901\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0357 - acc: 0.9877\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0317 - acc: 0.9895\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0286 - acc: 0.9899\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.0292 - acc: 0.9906\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0340 - acc: 0.9886\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0290 - acc: 0.9905\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0257 - acc: 0.9914\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 211s 4ms/step - loss: 0.0238 - acc: 0.9921\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 211s 4ms/step - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0306 - acc: 0.9898\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0204 - acc: 0.9932\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0181 - acc: 0.9937\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 0.0317 - acc: 0.9899\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0305 - acc: 0.9900\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0230 - acc: 0.9920\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0183 - acc: 0.9941\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0231 - acc: 0.9920\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0238 - acc: 0.9923\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0263 - acc: 0.9913\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0211 - acc: 0.9931\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 211s 4ms/step - loss: 0.0213 - acc: 0.9933\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0219 - acc: 0.9926\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0242 - acc: 0.9919\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0206 - acc: 0.9933\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0212 - acc: 0.9929\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0168 - acc: 0.9943\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0238 - acc: 0.9920\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0218 - acc: 0.9926\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0190 - acc: 0.9940\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0190 - acc: 0.9938\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0205 - acc: 0.9933\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0180 - acc: 0.9942\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0212 - acc: 0.9926\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0179 - acc: 0.9940\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0215 - acc: 0.9925\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0172 - acc: 0.9942\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0176 - acc: 0.9942\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0173 - acc: 0.9943\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0188 - acc: 0.9941\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0201 - acc: 0.9934\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0142 - acc: 0.9953\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0156 - acc: 0.9949\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0201 - acc: 0.9933\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0184 - acc: 0.9937\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0150 - acc: 0.9947\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0162 - acc: 0.9948\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0162 - acc: 0.9945\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 210s 4ms/step - loss: 0.0156 - acc: 0.9948\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0147 - acc: 0.9952\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0142 - acc: 0.9952\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0182 - acc: 0.9941\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0183 - acc: 0.9940\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0153 - acc: 0.9952\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0147 - acc: 0.9952\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 209s 4ms/step - loss: 0.0137 - acc: 0.9953\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 211s 4ms/step - loss: 0.0149 - acc: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee9fe626a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(5,5), input_shape=(32,32, 3), activation='relu'))\n",
    "#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "classifier.add(Convolution2D(64, kernel_size=(3,3), input_shape=(32,32, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(128, kernel_size=(3,3), input_shape=(32,32, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "classifier.add(Convolution2D(128, kernel_size=(3,3), input_shape=(32,32, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Convolution2D(256, kernel_size=(3,3), input_shape=(32,32, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim=100, activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10, activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train, y_train, batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 643,478\n",
      "Trainable params: 642,262\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5966358e-05, 1.9671254e-14, 4.9582699e-08, 9.6797144e-01,\n",
       "        2.1804448e-05, 8.1606200e-10, 5.0991090e-05, 2.0080491e-13,\n",
       "        3.1939752e-02, 1.6049372e-09]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example = (np.zeros(shape=(1,32,32,3)) - mean_train) / (std_train + 1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
